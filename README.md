## Twitter Guard Threat Scanner

#### Overview:
Within our project, we aim to create a threat-analysing scanner for Twitter. The scanner will be created as a web application that will allow users to scan accounts for potential threatening behaviour that is considered to be anti-social, and provide the user with a detailed report at the click of a button on what the algorithm has determined to be dangerous. The user then has the option to disregard the report, or review it and make changes based on what they consider to be the main threat.
Our web application will be named Tweet Guard Threat Scanner, and will aim to provide a user-friendly, quick environment that gives an accurate and detailed reflection of the threat or lack thereof that may lie within the user's Twitter followers.
Overall, the aim is to create a simple, sleek and minimalistic web app that offers users an easy way to filter out any negativity, antisocial behaviour or danger from their twitter feed with the click of a button. We aim to create an algorithm that is accurate, helpful and will grow stronger as more users use it.


#### Why is this needed:
In digital times, digital crimes are also rocketing. People need a way to keep themselves safe from online threats like sexual predators, fraud accounts, internet trolls, etc. Our web application will warn its users whenever a “threatening account” tries to interact with them. This will be perfect for people such as children, women and others who face the most threat online.

Twitter is an open platform where people can look at and talk about current affairs across the globe. With differing points of view, some people may have a perspective on a topic which might be controversial or offensive to other users. Some may also exploit the platform for malicious purposes.

Twitter has a system in place where if a user believes something violates the platform’s rules they can report it. This helps to indicate to the Twitter team that something is going on and they can then decide whether or not to take corrective measures. E.g. They may enforce a user to delete their Tweet, or suspend their account permanently (if a more serious/repeat offence is committed).
Violations are grouped under three separate categories:

1. Safety
This includes violent threats, terrorism, child sexual exploitation, harrassment, discriminational hate (e.g racism), intentions/encouragement of self-harm or suicide, sensitive media, and illegal activity.

2. Privacy
Includes disclosing other people’s private information, and non-consensual nudity.

3. Authenticity
Includes spam, civic integrity, impersonation, synthetic media, and copyright/trademark.

Although the reporting of these violations on Twitter helps to make the platform a safer place, there are a few problems that it does not address:

It is inefficient to depend on Twitter staff to go through each user report and  determine what action should be taken. This takes too long for threats to be identified and eliminated, meaning more users are vulnerable for a longer period.
Users will be completely oblivious to a harmful account as they cannot see if it has been previously reported before.
There is no threat alert so it is not obvious when a threat is received. Because of this, reporting is more likely to occur after harm is caused.
What some users don’t consider a threat, others might. Hence, smaller threats are often ignored, because there aren’t enough users reporting them.

The web application will quickly solve these problems:
Reported information is stored in a database, so threatening accounts can immediately be identified by users.
Users will now be able to scan for harmful accounts and see all details of previous reports.
Whenever a threatening appearing account tries to interact with a user, the user will be able to quickly discover if other people have had the same problem, or if our algorithms have detected said threatening behaviour. 
The web application will show a danger level so that threats of all sizes are accounted for. This allows users to make their own decisions on how restrictive they would like their account to be.


## Figma Link
https://www.figma.com/proto/TsOhGFEXfMAnvmyfFpfbXI/tsp2?node-id=0%3A3&frame-preset-name=Desktop&scaling=min-zoom


#### Overview - Roles

We analysed our strengths and weaknesses and for the next 2 weeks have allocated roles which will be reviewed and re-evaluated as the project progresses.

    Evan Dunbar - Sentiment Analysis research and development
    Conor McGavin - Back-end, infrastructure
    Conor Heeney - Front-end design and development
    Mark Daly - Front-end design and development
    Joel McKenna - API Research and Implementation, incl. Twitter APIs
    
We aim to understand each other’s roles and work closely and collaboratively to produce an environment where one team member will be able to work independently of another, but know what is expected of them to produce from other team members. This ensures fairness and that there is never one person that feels they are doing everything. We aim to closely follow a plan and reassess on a weekly basis on where the project is, and where it needs to be.





